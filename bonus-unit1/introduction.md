# 소개

![보너스 유닛 1 썸네일](https://huggingface.co/datasets/agents-course/course-images/resolve/main/en/bonus-unit1/thumbnail.jpg)

이 첫 번째 **보너스 유닛**에 오신 것을 환영합니다. 여기서는 **함수 호출을 위해 대규모 언어 모델(LLM)을 미세 조정**하는 방법을 배우게 됩니다.

LLM 측면에서 함수 호출은 빠르게 *필수* 기술이 되고 있습니다.

아이디어는 유닛 1에서 했던 것처럼 프롬프트 기반 접근 방식에만 의존하는 대신, 함수 호출은 모델이 **훈련 단계에서 조치를 취하고 관찰을 해석**하도록 훈련시켜 AI를 더욱 강력하게 만듭니다.

> **이 보너스 유닛은 언제 해야 하나요?**
>
> 이 섹션은 **선택 사항**이며 유닛 1보다 더 고급이므로 지금 이 유닛을 하거나 이 과정을 통해 지식이 향상되었을 때 다시 방문하는 것을 망설이지 마십시오.
>
> 하지만 걱정하지 마십시오. 이 보너스 유닛은 필요한 모든 정보를 담고 있도록 설계되었으므로, 아직 미세 조정의 내부 작동 방식을 배우지 않았더라도 함수 호출을 위한 모델 미세 조정의 모든 핵심 개념을 안내해 드립니다.

이 보너스 유닛을 따라갈 수 있는 가장 좋은 방법은 다음과 같습니다.

1. Transformers로 LLM을 미세 조정하는 방법을 알고 있어야 합니다. 그렇지 않은 경우 [이것을 확인하십시오](https://huggingface.co/learn/nlp-course/chapter3/1?fw=pt).

2. `SFTTrainer`를 사용하여 모델을 미세 조정하는 방법을 알고 있어야 합니다. 자세한 내용은 [이 설명서](https://huggingface.co/learn/nlp-course/en/chapter11/1)를 확인하십시오.

---

## 배우게 될 내용

1. **함수 호출**
   최신 LLM이 대화를 효과적으로 구조화하여 **도구**를 트리거하는 방법.

2. **LoRA(저순위 적응)**
   계산 및 저장 오버헤드를 줄이는 **가볍고 효율적인** 미세 조정 방법. LoRA는 대규모 모델을 *더 빠르고, 저렴하고, 쉽게* 배포할 수 있도록 합니다.

3. 함수 호출 모델의 **사고 → 행동 → 관찰 주기**
   모델이 함수를 호출할 시기(및 방법)를 결정하고, 중간 단계를 추적하고, 외부 도구 또는 API의 결과를 해석하는 방법을 구조화하기 위한 간단하지만 강력한 접근 방식.

4. **새로운 특수 토큰**
   모델이 다음을 구별하는 데 도움이 되는 **특수 마커**를 소개합니다.
   - 내부 "사고의 연쇄" 추론
   - 나가는 함수 호출
   - 외부 도구에서 돌아오는 응답

---

이 보너스 유닛이 끝나면 다음을 수행할 수 있습니다.

- 도구와 관련하여 API의 내부 작동 **이해**.
- LoRA 기술을 사용하여 모델 **미세 조정**.
- 강력하고 유지 관리 가능한 함수 호출 워크플로를 만들기 위해 사고 → 행동 → 관찰 주기를 **구현** 및 **수정**.
- 모델의 내부 추론을 외부 작업과 원활하게 분리하기 위해 특수 토큰을 **설계** 및 **활용**.

그리고 **함수 호출을 수행하도록 자신의 모델을 미세 조정하게 될 것입니다.** 🔥

**함수 호출**에 대해 자세히 알아보겠습니다!