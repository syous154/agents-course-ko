# 사고: 내부 추론 및 ReAct 접근 방식

<Tip>

이 섹션에서는 AI 에이전트의 내부 작동 방식, 즉 추론하고 계획하는 능력에 대해 자세히 알아봅니다. 에이전트가 내부 대화를 활용하여 정보를 분석하고, 복잡한 문제를 관리 가능한 단계로 분해하며, 다음에 어떤 조치를 취할지 결정하는 방법을 살펴봅니다.

또한, 모델이 행동하기 전에 "단계별로" 생각하도록 장려하는 프롬프트 기법인 ReAct 접근 방식을 소개합니다.

</Tip>

사고는 작업을 해결하기 위한 **에이전트의 내부 추론 및 계획 프로세스**를 나타냅니다.

이는 에이전트의 대규모 언어 모델(LLM) 역량을 활용하여 **프롬프트에 제시된 정보를 분석**합니다. 본질적으로 문제를 해결하는 과정에서의 내부 독백과 같습니다.

에이전트의 사고는 현재 관찰 내용을 평가하고 다음 행동을 결정하는 데 도움이 됩니다. 이 과정을 통해 에이전트는 **복잡한 문제를 더 작고 관리하기 쉬운 단계로 분해**하고, 과거 경험을 되돌아보며, 새로운 정보에 따라 계획을 지속적으로 조정할 수 있습니다.

## 🧠 일반적인 사고 유형의 예시

| 사고 유형        | 예시                                                                                             |
|--------------------|----------------------------------------------------------------------------------------------------|
| 계획 수립          | "이 작업을 세 단계로 나누어야 합니다: 1) 데이터 수집, 2) 추세 분석, 3) 보고서 생성" |
| 분석               | "오류 메시지를 기반으로 볼 때, 문제는 데이터베이스 연결 매개변수에 있는 것 같습니다" |
| 의사 결정          | "사용자의 예산 제약을 고려할 때, 중간 가격대의 옵션을 추천해야 합니다"                               |
| 문제 해결          | "이 코드를 최적화하려면 먼저 병목 현상을 식별하기 위해 프로파일링해야 합니다"                       |
| 기억 통합          | "사용자가 이전에 Python을 선호한다고 언급했으므로, Python으로 예시를 제공하겠습니다"           |
| 자기 성찰          | "이전 접근 방식이 잘 작동하지 않았으니, 다른 전략을 시도해야 합니다"                               |
| 목표 설정          | "이 작업을 완료하려면 먼저 승인 기준을 설정해야 합니다"                                           |
| 우선순위 지정        | "새로운 기능을 추가하기 전에 보안 취약점을 해결해야 합니다"                                       |

> **참고:** 함수 호출을 위해 미세 조정된 LLM의 경우, 사고 과정은 선택 사항입니다. 자세한 내용은 '행동' 섹션에서 다룰 예정입니다.

## 🔗 사고의 연쇄 (CoT)

**사고의 연쇄(CoT)**는 모델이 **최종 답변을 생성하기 전에 문제를 단계별로 생각하도록 안내하는** 프롬프트 기법입니다.

일반적으로 다음으로 시작합니다:
> *"단계별로 생각해 봅시다."*

이 접근 방식은 모델이 외부 도구와 상호 작용하지 않고도 특히 논리적 또는 수학적 작업에 대해 **내부적으로 추론**하는 데 도움이 됩니다.

### ✅ 예시 (CoT)
```
질문: 200의 15%는 얼마입니까?
사고: 단계별로 생각해 봅시다. 200의 10%는 20이고, 200의 5%는 10이므로, 15%는 30입니다.
답변: 30
```

## ⚙️ ReAct: 추론 + 행동

핵심적인 방법은 "추론"(생각)과 "행동"(실행)을 결합한 **ReAct 접근 방식**입니다.

ReAct는 모델이 단계별로 생각하고 추론 단계 사이에 (도구 사용과 같은) 행동을 교차하도록 장려하는 프롬프트 기법입니다.

이를 통해 에이전트는 다음을 번갈아 수행하며 복잡한 다단계 작업을 해결할 수 있습니다.
- 사고: 내부 추론
- 행동: 도구 사용
- 관찰: 도구 출력 수신

### 🔄 예시 (ReAct)
```
사고: 파리의 최신 날씨를 찾아야 합니다.
행동: Search["파리 날씨"]
관찰: 18°C이며 흐립니다.
사고: 이제 날씨를 알았으니...
행동: Finish["파리는 18°C이며 흐립니다."]
```

<figure>
  <img src="https://huggingface.co/datasets/agents-course/course-images/resolve/main/en/unit1/ReAct.png" alt="ReAct"/>
  <figcaption>
    (d)는 "단계별로 생각해 봅시다"라고 프롬프트하고 모델이 사고 사이에 행동하는 ReAct 접근 방식의 예시입니다.
  </figcaption>
</figure>

## 🔁 비교: ReAct vs. CoT

| 특징                 | 사고의 연쇄 (CoT)      | ReAct                               |
|----------------------|-----------------------------|-------------------------------------|
| 단계별 논리          | ✅ 예                       | ✅ 예                               |
| 외부 도구            | ❌ 아니오                   | ✅ 예 (행동 + 관찰)                 |
| 가장 적합한 용도     | 논리, 수학, 내부 작업       | 정보 탐색, 동적 다단계 작업         |

<Tip>

**Deepseek R1** 또는 **OpenAI의 o1**과 같은 최신 모델은 *답변하기 전에 생각하도록* 미세 조정되었습니다. 이들은 `<think>` 및 `</think>`와 같은 구조화된 토큰을 사용하여 추론 단계를 최종 답변과 명시적으로 분리합니다.

ReAct 또는 CoT와 같은 프롬프트 전략과 달리, 이는 모델이 예시를 통해 생각하는 방법을 배우는 **훈련 수준의 기술**입니다.

</Tip>